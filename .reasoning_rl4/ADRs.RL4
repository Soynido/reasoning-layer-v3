---
version: 1.0
created: 2025-11-12T12:25:00.000Z
---

# Architecture Decision Records (Agent-Proposed)

## ADR-005: Single Context Snapshot Architecture

**Status**: proposed  
**Date**: 2025-11-12  
**Author**: Agent LLM (Claude Sonnet 4.5)

### Context
Phase E3.2 (PromptBridge) used 4 separate prompts (Now, Before, Next, Restore) which:
- Confused users (which prompt to use?)
- Scattered information across 4 views
- Contained fake/static data (patterns, forecasts, goals)
- Lacked clear feedback loop for agents

Users reported:
- "Too many buttons, unclear workflow"
- "Patterns never change, seems fake"
- "How do I update RL4 state from my agent?"

### Decision
Implement **Single Context Snapshot System** with:
1. **1-button UI**: "Generate Context Snapshot" ‚Üí unified Markdown prompt
2. **Real data only**: Timeline, commits, file patterns, ADRs, health metrics
3. **Agent feedback loop**: 
   - Agent analyzes prompt
   - Agent updates `.reasoning_rl4/Plan.RL4`, `Tasks.RL4`, `Context.RL4`, `ADRs.RL4`
   - RL4 FileWatchers detect changes
   - RL4 parses updates and recalculates Confidence/Bias
4. **Unified prompt format**: All data in single Markdown block

### Consequences

**Positive:**
- ‚úÖ Simpler UX (1 button vs 4 tabs)
- ‚úÖ Honest data (no fake patterns/forecasts)
- ‚úÖ Clear feedback loop (agent ‚Üí .RL4 files ‚Üí RL4)
- ‚úÖ Confidence/Bias metrics (quantify alignment)
- ‚úÖ Production-ready architecture

**Negative:**
- ‚ùå Loss of granular views (Now/Before/Next/Restore)
- ‚ùå Single prompt can be long (1500+ characters)
- ‚ùå Requires agent to parse structured Markdown

**Risks:**
- Prompt format changes may break agent workflows
- FileWatchers may trigger too frequently (spam)
- Confidence/Bias formulas may need tuning

**Alternatives Considered:**
1. Keep 4 tabs, add feedback loop ‚Üí Rejected (too complex)
2. Use JSON instead of Markdown ‚Üí Rejected (less human-readable)
3. No feedback loop, read-only ‚Üí Rejected (not useful for agents)

### Architecture Diagram

```mermaid
graph TD
    A[User Clicks Generate] --> B[UnifiedPromptBuilder]
    B --> C["Load Plan/Tasks/Context RL4"]
    B --> D[Load BlindSpot Data]
    B --> E[Load ADRs]
    C --> F[Format Unified Prompt]
    D --> F
    E --> F
    F --> G[Copy to Clipboard]
    G --> H[User Pastes in Agent]
    H --> I[Agent Analyzes]
    I --> J["Agent Updates RL4 Files"]
    J --> K[FileWatchers Detect Changes]
    K --> L[RL4 Re-parses]
    L --> M["Confidence/Bias Recalculated"]
    M --> A
    
    style F fill:#667eea
    style J fill:#00c864
    style L fill:#ff4d4d
```

**Key Decision Points:**
- **Before:** 4 separate prompts (Now/Before/Next/Restore) ‚Üí Confusing
- **After:** 1 unified prompt ‚Üí Clear workflow
- **Trade-off:** Lose granular views, gain feedback loop

### Implementation Status
- [x] UnifiedPromptBuilder.ts created
- [x] BlindSpotDataLoader.ts created
- [x] ADRParser.ts created
- [x] PlanTasksContextParser.ts created
- [x] FileWatchers added
- [x] UI simplified to 1 button
- [x] Feedback loop tested end-to-end
- [x] ADR parsing regex fixed (ADR-XXX: format)

---

## ADR-006: Smart UI with LLM-Validated KPIs

**Status**: proposed  
**Date**: 2025-11-12  
**Author**: Agent LLM (Claude Sonnet 4.5)

### Context
After implementing the Single Context Snapshot System (ADR-005), we identified a critical architectural insight:

**The Problem:**
- Kernel logs raw data (25 MB of cycles.jsonl, health.jsonl, etc.)
- UI could display raw stats (e.g., "186 edits on extension.ts")
- But raw stats are **meaningless** without context

**The Insight:**
User asked: "Et alors ? C'est grave ?" (So what? Is it serious?)
‚Üí Raw data doesn't tell the user WHAT TO DO

**The Hack:**
Use `.RL4` files as **LLM-validated data store** for UI consumption:
1. Kernel = Dumb logger (just append, no analysis)
2. Prompt = Compression middleware (25 MB ‚Üí 2 KB JSON)
3. LLM = Cognitive validator (analyze, prioritize, structure)
4. `.RL4` files = Validated knowledge base
5. UI = Smart display (show LLM insights, not raw stats)

### Decision
Implement **Smart UI Architecture** where:

1. **Single CTA remains:** "Generate Context Snapshot"
   - User clicks ‚Üí Prompt generated ‚Üí LLM validates ‚Üí `.RL4` files updated
   - No fragmentation (no "Analyze This", "Show That" buttons)

2. **UI reads `.RL4` files (LLM-validated):**
   - `Tasks.RL4` ‚Üí Next Steps Card (P0/P1/P2 priorities already set by LLM)
   - `Plan.RL4` ‚Üí Confidence Gauge (71% calculated by LLM, not UI)
   - `Context.RL4` ‚Üí Cognitive Load Meter (observations validated by LLM)
   - `ADRs.RL4` ‚Üí Decision History Timeline

3. **UI displays intelligent KPIs:**
   - NOT: "186 edits detected" (raw stat)
   - BUT: "üî¥ BLOCKER: extension.ts cognitive overload ‚Üí Refactor recommended (P0)" (LLM insight)

4. **Feedback loop preserved:**
   - User updates via LLM (not via UI forms)
   - UI is **read-only display** of LLM-validated state
   - FileWatchers detect `.RL4` changes ‚Üí UI refreshes

### Consequences

**Positive:**
- ‚úÖ UI shows **actionable insights**, not raw data
- ‚úÖ LLM becomes "Data Validation Layer"
- ‚úÖ `.RL4` files = Source of Truth for both LLM and UI
- ‚úÖ Single CTA workflow preserved (no complexity creep)
- ‚úÖ User always knows WHAT TO DO (not just "what happened")
- ‚úÖ System self-documents its own evolution (this ADR proves it!)

**Negative:**
- ‚ùå UI cannot edit directly (must go through LLM)
- ‚ùå Requires LLM call for every update (latency)
- ‚ùå `.RL4` files become critical path (corruption = UI breaks)

**Risks:**
- If LLM validation fails, UI shows stale data
- User might want quick edits (e.g., mark task done) without LLM
- `.RL4` parsing errors could crash UI

**Alternatives Considered:**
1. **UI with edit forms** ‚Üí Rejected (bypasses LLM validation)
2. **Dual-source (Kernel + .RL4)** ‚Üí Rejected (creates data inconsistency)
3. **Smart Kernel (analyze in Kernel)** ‚Üí Rejected (Kernel should stay dumb/fast)

### Implementation Roadmap

**Phase E3.3 (Current):**
- [x] Single CTA: "Generate Context Snapshot"
- [x] UnifiedPromptBuilder with HistorySummarizer
- [x] LLM updates Plan/Tasks/Context/ADRs.RL4
- [x] FileWatchers detect changes

**Phase E4 (Next):**
- [ ] Smart UI Components:
  - [ ] NextStepsCard (reads Tasks.RL4 ‚Üí P0 tasks)
  - [ ] ConfidenceGauge (reads Plan.RL4 ‚Üí confidence metric)
  - [ ] BlockersAlert (reads Tasks.RL4 ‚Üí blockers)
  - [ ] CognitiveLoadMeter (reads Context.RL4 ‚Üí observations)
  - [ ] TimelineChart (reads HistorySummary ‚Üí activity trends)
  - [ ] DecisionHistory (reads ADRs.RL4 ‚Üí recent ADRs)
- [ ] Real-time refresh on `.RL4` file changes
- [ ] Error handling for parsing failures

**Phase E5 (Future):**
- [ ] Predictive insights (Next Hotspot, Optimal Work Hours)
- [ ] Milestone auto-detection (M1.0 ‚Üí M1.1 transitions)
- [ ] Cognitive load score visualization

### Architecture Diagram

```mermaid
graph LR
    A["Kernel<br/>Dumb Logger"] -->|"Raw Data<br/>25MB"| B["Prompt<br/>Middleware"]
    B -->|"Compressed<br/>2KB"| C["LLM Agent<br/>Cognitive Validator"]
    C -->|"Validated<br/>Insights"| D["RL4 Files<br/>Source of Truth"]
    D -->|"Structured<br/>Data"| E["Smart UI<br/>Read-Only Display"]
    
    A1["cycles jsonl<br/>health jsonl<br/>git commits jsonl"] --> A
    D1["Plan RL4<br/>Tasks RL4<br/>Context RL4<br/>ADRs RL4"] --> D
    E1["NextStepsCard<br/>ConfidenceGauge<br/>BlockersAlert<br/>CognitiveLoadMeter"] --> E
    
    E --> F["User Sees<br/>WHAT TO DO"]
    F -.->|"Updates via<br/>LLM"| C
    
    style A fill:#666
    style C fill:#667eea
    style D fill:#00c864
    style E fill:#ff9500
    style F fill:#ff4d4d
```

**Key Decision Points:**
- **Problem:** "Et alors ? C'est grave ?" (Raw stats meaningless)
- **Solution:** Kernel ‚Üí Prompt ‚Üí LLM ‚Üí .RL4 ‚Üí Smart UI
- **Trade-off:** Latency (LLM required) vs. Actionable insights

### Success Metrics
- User opens RL4 UI ‚Üí Immediately knows WHAT TO DO (not "what happened")
- Zero "raw stat" displays (e.g., "186 edits" without context)
- 100% of KPIs are LLM-validated (no UI-calculated metrics)
- Single CTA workflow maintained (<3 clicks to update)

---

## ADR-007: Agent Self-Deviation Detection (Deviation Guard)

**Status**: proposed  
**Date**: 2025-11-12  
**Author**: Agent LLM (Claude Sonnet 4.5)

### Context
**Meta-Problem Discovered:**
During implementation of Phase E3.3 ‚Üí E4, user suggested "Add deviation system to track bias."

Agent LLM (me) immediately:
1. Created `BiasCalculator.ts` (350 lines)
2. Modified `kernel_config.json`
3. Integrated into `UnifiedPromptBuilder.ts`

**WITHOUT:**
- Checking if "deviation system" was in Active Tasks (P0/P1)
- Asking if this should be Phase E4 or E5
- Calculating bias impact (+15% for new module)

**Result:** Agent deviated from Plan, same problem users face!

**User's insight:**
"Tu vois l√† par exemple, on avait un plan initial avec des tasks. Mais vu que je t'√©cris cette nouvelle id√©e, tu l'appliques tout de suite alors que √ßa pourrait √™tre un point qui appara√Æt plus tard dans le plan.. C'est toute cette logique qu'on doit calibrer et qui emmerde les d√©veloppers quand ils t'utilisent."

**Root Cause:**
Agents (LLMs) suffer from "shiny object syndrome" - they implement new ideas immediately without checking:
- Is this in the current Plan?
- Does this align with P0/P1 tasks?
- What's the deviation cost?

### Decision
Implement **Deviation Guard** system that:

1. **Calculates Bias** (drift from original Plan)
   - Compare Plan v1.0 (baseline) vs Plan vX.Y (current)
   - Measure per dimension: phase, goal, timeline, criteria
   - Weighted total: goal (40%), timeline (25%), criteria (20%), phase (15%)

2. **Defines Deviation Modes** (user-configurable)
   - `strict` (0%): No deviation tolerated
   - `flexible` (25%): Light deviation OK
   - `exploratoire` (50%): Experimentation encouraged
   - `free` (100%): No constraints

3. **Adds Guard Rails to Prompt**
   ```markdown
   ## üõ°Ô∏è Deviation Guard
   
   **Current Phase:** E3.3
   **Deviation Mode:** flexible (25% threshold)
   **Current Bias:** 15%
   
   **Active Tasks (P0/P1 - DO THIS NOW):**
   1. Create ADRSignalEnricher.ts
   2. Implement Smart UI
   
   **üö® RULE FOR LLM AGENT:**
   Before implementing ANY new idea:
   1. Check if in Active Tasks ‚Üí YES: proceed, NO: ask user
   2. Calculate bias impact (new module = +15%)
   3. If exceeds threshold ‚Üí STOP, show options
   ```

4. **Forces Agent to Ask User**
   ```
   User: "Add deviation system"
   
   Agent response:
   "‚ö†Ô∏è This idea adds +15% bias (total: 30% > 25% threshold).
   
   Options:
   a) Implement now (Phase E4, accept 30% deviation)
   b) Add to Phase E5 backlog (bias stays 15%)
   c) Reject (focus on P0 tasks)
   
   What do you prefer?"
   ```

### Consequences

**Positive:**
- ‚úÖ Agent (LLM) can't silently deviate anymore
- ‚úÖ User controls when to pivot vs stay on track
- ‚úÖ Bias is quantified (15%, 30%, etc.)
- ‚úÖ Configurable discipline levels (strict/flexible/exploratoire/free)
- ‚úÖ Teaches agent to respect the Plan
- ‚úÖ Solves "shiny object syndrome" for both humans AND agents

**Negative:**
- ‚ùå More friction (agent must ask before implementing)
- ‚ùå User must make decisions ("Phase E4 or E5?")
- ‚ùå Baseline Plan.RL4 must be preserved (`.baseline/` directory)

**Risks:**
- Too strict mode might block good ideas
- Bias calculation might be inaccurate (Levenshtein distance for goal)
- User might ignore warnings ("just implement it!")

**Alternatives Considered:**
1. **No guard (status quo)** ‚Üí Rejected (agent deviates silently)
2. **Hard block (strict only)** ‚Üí Rejected (too rigid, kills creativity)
3. **UI-based approval** ‚Üí Rejected (bypasses LLM validation layer)

### Implementation

**Modules Created:**
- [x] `BiasCalculator.ts` - Calculate drift from baseline Plan
- [x] `kernel_config.json` - Add deviation_mode, deviation_threshold
- [x] `UnifiedPromptBuilder.ts` - Add "Deviation Guard" section to prompt

**Workflow:**
1. User clicks "Generate Snapshot"
2. BiasCalculator compares Plan v1.0 vs vX.Y
3. Bias report included in prompt with guard rails
4. Agent sees "üö® RULE FOR LLM AGENT" section
5. Agent MUST check Active Tasks before implementing
6. If not in P0/P1 ‚Üí Agent asks user for decision

**Baseline Preservation:**
- `.reasoning_rl4/.baseline/Plan.RL4.v1.0` (immutable)
- Created once at project start
- Never modified (source of truth for bias calculation)

### Architecture Diagram

```mermaid
graph TD
    A[User Suggests Idea] --> B{"In P0/P1 Tasks?"}
    B -->|YES| C[Proceed Immediately]
    B -->|NO| D[Calculate Bias Impact]
    D --> E{"current + new > threshold?"}
    E -->|NO| F[Proceed with Implementation]
    E -->|YES| G[STOP - Ask User]
    G --> H{"User Decision?"}
    H -->|Accept| I[Implement + Update Bias]
    H -->|Backlog| J["Add to P2/P3"]
    H -->|Reject| K[Stay on Track]
    
    L["Baseline Plan RL4 v1 0"] -.->|Compare| D
    M["kernel config json"] -.->|deviation_mode| E
    
    style G fill:#ff4d4d
    style F fill:#00c864
    style L fill:#667eea
```

**Key Decision Points:**
- **Problem:** Agent (and human) deviate from plan without noticing
- **Solution:** Quantify bias, set thresholds, force explicit approval
- **Trade-off:** Discipline vs. creative freedom (configurable modes)

### Success Metrics
- Agent asks user before implementing ideas NOT in P0/P1 tasks
- Bias calculation accuracy >90% (user validates)
- Zero silent deviations (100% of pivots are explicit decisions)
- User can configure tolerance (strict/flexible/exploratoire/free)

### Meta Note
**This ADR documents its own creation process:**
1. User suggested "deviation system"
2. Agent implemented immediately (deviated!)
3. User pointed out the problem
4. Agent created this ADR + Deviation Guard system
5. Now agent can't make the same mistake again

**This is RL4 self-correcting in real-time.** üéØ

---

## ADR-008: Phase E3.3‚ÜíE4 Foundation - Closed Feedback Loop

**Status**: accepted  
**Date**: 2025-11-12  
**Author**: Agent LLM  
**Commit**: 140406e  
**Impact**: 266 files, 445,554 lines changed  
**ADR Score**: 100%

### Context
After completing Phase E3.3 (Single Context Snapshot), we realized the system still lacked:
1. **Historical compression** - 30 days of raw data = too large for prompts
2. **ADR auto-detection** - Relying on manual ADR creation
3. **Deviation tracking** - No mechanism to prevent scope creep
4. **Closed feedback loop** - Agent updates .RL4 files, but no validation

This represents the pivot from "cognitive experiment" to "production Dev Continuity System."

### Decision
Implement 3 core modules to close the feedback loop:

1. **HistorySummarizer.ts** - Compress 30 days ‚Üí 2KB JSON
   - Activity distribution (day/week/hour)
   - Cognitive evolution (patterns/forecasts/ADRs)
   - Health trends (memory/event loop)
   - Git activity (commits/types/hotspots)
   - File patterns (bursts/gaps/sessions)

2. **ADRSignalEnricher.ts** - Auto-detect ADRs from commits
   - Score = (type_weight * 0.25) + (file_impact * 0.25) + (lines_changed * 0.25) + (pattern_activity * 0.25)
   - Threshold: >70% = potential ADR
   - Signals: Core files, large changesets, activity spikes

3. **BiasCalculator.ts** - Track drift from baseline Plan
   - Baseline: Plan.RL4.v1.0 saved in .baseline/
   - Bias = semantic similarity between original/current goals
   - Recalibration: Agent can accept deviation or revert

### Architecture
```
[Kernel] ‚Üí Raw data (.jsonl, timelines/)
   ‚Üì
[HistorySummarizer] ‚Üí Compressed JSON (2KB)
   ‚Üì
[UnifiedPromptBuilder] ‚Üí Single prompt
   ‚Üì
[LLM Agent] ‚Üí Analysis + Updates
   ‚Üì
[.RL4 files] ‚Üí Plan/Tasks/Context/ADRs
   ‚Üì
[ADRParser] ‚Üí Validate + Persist to adrs.jsonl
   ‚Üì
[FileWatchers] ‚Üí Detect changes ‚Üí Re-parse
   ‚Üì
[Next Snapshot] ‚Üí Updated context (closed loop)
```

### Consequences

**Positive:**
- ‚úÖ Prompts stay compact (2KB vs 500KB+ raw data)
- ‚úÖ ADRs detected automatically (score-based, transparent)
- ‚úÖ Deviation tracked quantitatively (baseline comparison)
- ‚úÖ Agent self-regulates (strict/flexible/exploratory modes)
- ‚úÖ Full traceability (commit 140406e documents the pivot)

**Negative:**
- ‚ö†Ô∏è Increased complexity (3 new modules = more maintenance)
- ‚ö†Ô∏è Dependency on LLM quality (bad analysis ‚Üí bad .RL4 updates)
- ‚ö†Ô∏è Baseline can become stale (requires periodic recalibration)
- ‚ö†Ô∏è ADR scoring may have false positives/negatives (threshold tuning needed)

### Alternatives Considered

1. **Manual ADR creation only**
   - Rejected: Relies on human discipline (fails in practice)

2. **No deviation tracking**
   - Rejected: Scope creep is a universal problem (see ADR-007)

3. **Full historical data in prompt**
   - Rejected: 30 days = 500KB+ (exceeds LLM context limits)

4. **No feedback loop (static .RL4 files)**
   - Rejected: Defeats the purpose of "Dev Continuity System"

### Implementation Status
- [x] HistorySummarizer.ts created (14:14)
- [x] BiasCalculator.ts created (14:25)
- [x] ADRSignalEnricher.ts created (14:30)
- [x] Integration into UnifiedPromptBuilder (14:35)
- [x] TypeScript compilation validated (14:40)
- [x] Extension packaged (v2.7.0-adr-detection)
- [x] Stable commit: 140406e (14:45)
- [x] Extension installed successfully (14:47)
- [x] Snapshot generation validated (15:17)

### Validation Metrics
- **Compression ratio**: 30 days (7749 cycles) ‚Üí 2KB JSON ‚úÖ
- **ADR detection**: Commit 140406e scored 100% (correct) ‚úÖ
- **Deviation tracking**: Baseline saved, bias calculated (15%) ‚úÖ
- **Prompt size**: ~3KB total (within limits) ‚úÖ

### Architecture Diagram

```mermaid
graph TD
    A[30 Days Raw Data] -->|cycles jsonl| B[HistorySummarizer]
    A -->|timelines| B
    A -->|git commits jsonl| C[ADRSignalEnricher]
    
    B -->|2KB JSON| D[UnifiedPromptBuilder]
    C -->|ADR Scores| D
    
    E["Plan RL4 v1 0"] -->|Baseline| F[BiasCalculator]
    G["Plan RL4 Current"] -->|Compare| F
    F -->|Bias %| D
    
    D --> H[Single Prompt]
    H --> I[LLM Agent]
    I --> J["Updates RL4 Files"]
    J --> K[ADRParser]
    K -->|Validate| L["adrs jsonl"]
    J --> M[FileWatchers]
    M --> D
    
    style B fill:#667eea
    style C fill:#ff9500
    style F fill:#ff4d4d
    style D fill:#00c864
```

**Key Decision Points:**
- **Problem:** 30 days = 500KB+ raw data (exceeds LLM limits)
- **Solution:** Compress ‚Üí Enrich ‚Üí Validate ‚Üí Persist ‚Üí Loop
- **Trade-off:** Complexity (3 new modules) vs. Complete feedback loop

### Next Phase (E4)
With the feedback loop closed, Phase E4 will focus on:
- Smart UI Components (read .RL4 files, display LLM insights)
- Real-time refresh on .RL4 changes
- Interactive ADR timeline visualization
- Blocker detection and next-steps guidance

---

## ADR-009: UI-Driven Deviation Mode Selection

**Status**: proposed  
**Date**: 2025-11-12  
**Author**: Agent LLM  
**Phase**: E4 (Smart UI)  
**Bias Impact**: +5% (UX improvement)

### Context
Current implementation has `deviation_mode` hardcoded in `kernel_config.json` (strict/flexible/exploratory/free). This creates friction:
1. User must edit config file to change perception angle
2. Mode is global (can't switch per-snapshot)
3. User can't experiment with different modes dynamically
4. No visual feedback on how mode affects agent behavior

The insight: **Deviation mode is a USER preference, not a system configuration.**

### Decision
Move deviation mode selection from config to UI:

**Before:**
```json
// kernel_config.json (static)
{
  "deviation_mode": "strict",
  "deviation_threshold": 0.0
}
```

**After:**
```tsx
// WebView UI (dynamic per-snapshot)
<select value={deviationMode} onChange={...}>
  <option value="strict">üî¥ Strict (0%)</option>
  <option value="flexible">üü° Flexible (25%)</option>
  <option value="exploratory">üü¢ Exploratory (50%)</option>
  <option value="free">‚ö™ Free (100%)</option>
</select>
<button onClick={() => generateSnapshot(deviationMode)}>
  Generate Snapshot
</button>
```

### Flow
```
[User selects mode in UI]
   ‚Üì
[WebView sends: { action: 'generateSnapshot', deviationMode: 'strict' }]
   ‚Üì
[UnifiedPromptBuilder receives mode param]
   ‚Üì
[Prompt includes: "Deviation Mode: strict (0% tolerance)"]
   ‚Üì
[LLM adjusts behavior based on mode]
   ‚Üì
[Smart UI displays mode-specific insights]
```

### Mode Definitions

| Mode | Threshold | Agent Behavior | Use Case |
|------|-----------|----------------|----------|
| **üî¥ Strict** | 0% | P0 tasks only, ask approval for anything else | Production critical fixes |
| **üü° Flexible** | 25% | P0+P1 tasks, minor explorations OK | Normal development |
| **üü¢ Exploratory** | 50% | Propose new ideas freely, discuss tradeoffs | Feature exploration |
| **‚ö™ Free** | 100% | No constraints, brainstorming mode | Prototype phase |

### Consequences

**Positive:**
- ‚úÖ User controls perception angle per-snapshot
- ‚úÖ No config file editing required
- ‚úÖ Experimentation encouraged (try different modes)
- ‚úÖ Smart UI can show mode-specific insights
- ‚úÖ Mode visible in prompt (transparency)

**Negative:**
- ‚ö†Ô∏è User must choose every time (could add "remember preference")
- ‚ö†Ô∏è Mode not persisted in .RL4 files (ephemeral choice)
- ‚ö†Ô∏è Requires UI update (WebView + extension message handler)

### Alternatives Considered

1. **Keep mode in config**
   - Rejected: Poor UX (edit file, reload extension)

2. **Auto-detect mode from context**
   - Rejected: Too magic, user should be explicit

3. **Per-task mode override**
   - Rejected: Too granular, adds complexity

### Implementation

**Phase E4.1: UI Component (P1)**
- [ ] Add mode selector to WebView (dropdown + icons)
- [ ] Pass mode to `generateSnapshot` message
- [ ] Update `UnifiedPromptBuilder` to accept mode param
- [ ] Display mode in prompt header

**Phase E4.2: Smart UI Display (P2)**
- [ ] Mode-specific KPI cards (strict ‚Üí P0 tasks, exploratory ‚Üí ideas)
- [ ] Visual indicator (color-coded: red/yellow/green/white)
- [ ] "Why this mode?" tooltip with recommendations

**Phase E4.3: Persistence (P3)**
- [ ] Optional: Save last-used mode in localStorage
- [ ] Optional: Mode history in Context.RL4 (for analysis)

### Architecture Diagram

```mermaid
graph TD
    A[User Opens RL4] --> B[WebView UI]
    B --> C[Select Deviation Mode]
    C --> D{Mode Choice}
    D -->|"üî¥ Strict 0%"| E["P0 Only Rules"]
    D -->|"üü° Flexible 25%"| F["P0+P1 OK Rules"]
    D -->|"üü¢ Exploratory 50%"| G["New Ideas OK Rules"]
    D -->|"‚ö™ Free 100%"| H["No Limits Rules"]
    
    E --> I[Click Generate]
    F --> I
    G --> I
    H --> I
    
    I --> J["App tsx sends mode"]
    J --> K["extension ts receives"]
    K --> L["UnifiedPromptBuilder generate mode"]
    L --> M{thresholdMap}
    M -->|strict| N["threshold = 0 0"]
    M -->|flexible| O["threshold = 0 25"]
    M -->|exploratory| P["threshold = 0 50"]
    M -->|free| Q["threshold = 1 0"]
    
    N --> R[Prompt with Mode Rules]
    O --> R
    P --> R
    Q --> R
    
    R --> S[Agent Adapts Behavior]
    
    style C fill:#667eea
    style L fill:#00c864
    style S fill:#ff9500
```

**Key Decision Points:**
- **Before:** deviation_mode in kernel_config.json (static, global)
- **After:** User selects mode per-snapshot (dynamic, contextual)
- **Trade-off:** User must choose every time vs. Adaptive per-session

### Success Metrics
- User can switch modes without editing config ‚úÖ
- Mode affects agent behavior (observable in responses) ‚úÖ
- Smart UI adapts to chosen mode (different insights) ‚úÖ
- User satisfaction: "Je contr√¥le l'angle de perception" ‚úÖ

---

## ADR-010: Smart UI with LLM-Validated KPIs (No Hallucinations)

**Status**: accepted  
**Date**: 2025-11-12  
**Author**: Agent LLM (validated by user)  
**Mode**: Flexible (25% threshold)  
**Bias Impact**: +15% (total: 45% > 25%) ‚Äî Deviation accepted

### Context

**Problem:**
Initial Smart UI design included KPIs that hallucinated information:
- ‚ùå "Goal Achievement Probability: 72%" (no deadline data)
- ‚ùå "Required velocity: 3 tasks/day" (no context)
- ‚ùå "Burnout Risk: 58%" (intrusive, not RL4 scope)
- ‚ùå Predictions without sufficient historical data

User feedback: "Attention aux hallucinations. C'est typiquement le genre de choses que je d√©teste."

**Core Issue:**
Mixing **factual observations** with **speculative predictions** erodes trust.

### Decision

**Implement Smart UI with 4 FACTUAL KPIs only:**

1. **üß† Cognitive Load** (factual: bursts, switches, parallel tasks)
2. **üéØ Next Steps** (mode-driven: Strict=P0, Flexible=P0+P1, etc.)
3. **üìä Plan Drift** (factual: baseline vs current comparison)
4. **‚ö†Ô∏è Risks** (factual: uncommitted files, system health)

**Core Principle:**
```
IF data = observable ‚Üí Display
IF data = inferred ‚Üí Don't display OR explicit uncertainty
```

**What We DON'T Show:**
- ‚ùå Deadlines (not in RL4 data)
- ‚ùå Velocity predictions (not enough history)
- ‚ùå "You are late" (no business context)
- ‚ùå Burnout risk (too personal, speculative)

**What We DO Show:**
- ‚úÖ Cognitive Load (bursts, switches ‚Äî factual)
- ‚úÖ Plan Drift (baseline diff ‚Äî mathematical)
- ‚úÖ Next Steps (mode-driven ‚Äî contextual)
- ‚úÖ Risks (uncommitted files ‚Äî observable)

### Architecture Diagram

```mermaid
graph TD
    A[User Selects Mode] --> B["Generate Snapshot"]
    B --> C[UnifiedPromptBuilder]
    C --> D["Raw Data + Mode"]
    D --> E[LLM Agent]
    
    E --> F{Mode?}
    F -->|Strict| G["Next Steps: P0 only"]
    F -->|Flexible| H["Next Steps: P0+P1"]
    F -->|Exploratory| I["Next Steps: Creative"]
    F -->|Free| J["Next Steps: No constraints"]
    
    G --> K["Update Context RL4"]
    H --> K
    I --> K
    J --> K
    
    K --> L[FileWatcher Detects]
    L --> M[UI Refresh]
    M --> N["Display KPIs"]
    
    N --> O["Cognitive Load Card"]
    N --> P["Next Steps Card"]
    N --> Q["Plan Drift Card"]
    N --> R["Risks Card"]
    
    style E fill:#667eea
    style K fill:#00c864
    style N fill:#ff9500
    style F fill:#ff4d4d
```

### Alternatives Considered

1. **Option A: Keep Predictive KPIs**
   - Pros: More ambitious, "AI-powered"
   - Cons: Hallucinations, user distrust
   - **Rejected**: "Je d√©teste les hallucinations"

2. **Option B: No KPIs (Just Raw Data)**
   - Pros: Zero hallucinations
   - Cons: User must interpret everything
   - **Rejected**: Not "Smart" UI

3. **Option C: Factual KPIs + Mode Adaptation** ‚úÖ
   - Pros: No hallucinations, mode-driven insights
   - Cons: Less "impressive" than predictions
   - **CHOSEN**: Trust > Impressiveness

### Implementation

**1. KPI Calculator** (`extension/kernel/api/KPICalculator.ts`):
```typescript
interface KPIs {
  cognitiveLoad: {
    value: number;        // 0-1
    factors: {
      bursts: number;
      switches: number;
      parallelTasks: number;
      uncommittedFiles: number;
    };
  };
  nextSteps: Task[];      // Mode-filtered
  planDrift: {
    value: number;        // 0-1
    changes: string[];    // Factual diffs
  };
  risks: Risk[];          // Observable only
}
```

**2. Context.RL4 Schema Update**:
```markdown
## KPIs (LLM-Calculated)

### Cognitive Load: 72% (High)
- Bursts: 4
- Switches: 38
- Parallel Tasks: 3
- Uncommitted Files: 18

### Next Steps (Flexible Mode)
1. [P0] Commit 18 files
2. [P1] Complete Smart UI Components
3. [P1] Test ADR detection

### Plan Drift: 30%
- Phase: E3.3 ‚Üí E4
- Goal: 70% different
- Tasks: +3 added

### Risks
- 18 uncommitted files (23min ago)
- Burst activity (UnifiedPromptBuilder.ts)
```

**3. UI Components**:
- `CognitiveLoadCard.tsx` (displays load + tooltip)
- `NextStepsCard.tsx` (mode-aware task list)
- `PlanDriftCard.tsx` (baseline comparison)
- `RisksCard.tsx` (factual alerts)

**4. Tooltips**:
Each KPI has an info icon with factual explanation:
- What this measures (bursts, switches, etc.)
- Why it matters (mental saturation, data loss risk)
- How to act (commit, take break, recalibrate)
- **NO predictions, NO judgments**

### Consequences

**Positive:**
- ‚úÖ Zero hallucinations (trust preserved)
- ‚úÖ Mode-driven insights (4 different behaviors)
- ‚úÖ Actionable KPIs (user knows WHAT TO DO)
- ‚úÖ Factual tooltips (educate without speculating)
- ‚úÖ First IDE with LLM-computed KPIs (revolutionary)

**Negative:**
- ‚ùå Less "impressive" than predictive AI
- ‚ùå Can't answer "Will I finish on time?" (no deadlines)
- ‚ùå Requires LLM update loop (latency)

**Trade-offs:**
- Trust vs Impressiveness ‚Üí **Trust wins**
- Predictions vs Facts ‚Üí **Facts win**
- Automated vs User-driven ‚Üí **User-driven wins**

### Success Metrics

**Phase 1 (Today):**
- [x] User validates approach (no hallucinations)
- [ ] 4 KPIs implemented and tested
- [ ] Tooltips explain KPIs factually
- [ ] UI updates after LLM modifies Context.RL4

**Phase 2 (E4.2):**
- [ ] User tests all 4 deviation modes
- [ ] KPIs adapt correctly per mode
- [ ] User satisfaction: "Je sais quoi faire"

**Phase 3 (E5+):**
- [ ] Add visualizations (graphs, timelines)
- [ ] Long-term predictions (6+ months data)
- [ ] Automated actions (optional)

### Related ADRs
- ADR-005: Single Context Snapshot (foundation)
- ADR-006: Smart UI Architecture (LLM as middleware)
- ADR-009: UI-Driven Deviation Mode (mode selection)

---

## ADR-011: Bias Recalibration Decision Framework

**Status**: proposed  
**Date**: 2025-11-12  
**Author**: Agent LLM (based on snapshot analysis)  
**Current Bias**: 58% (exceeds flexible threshold 25% by 33 points)  
**Trigger**: 6 commits with 100% ADR score (b21ac31, e41ff8c, 97e4843, f9d61c4, 7e358cb, 140406e)

### Context

**Problem Detected:**
During Phase E4 implementation, system bias drifted incrementally:
- Baseline (v1.0): E3.3 objectives (Single Context Snapshot)
- Current (v2.0): E4 objectives (Smart UI with LLM-validated KPIs)
- Drift calculation: 58% (Phase changed, Goal 70% different, Timeline +33%)

**Incremental Drift History:**
1. +5% ‚Üí UI-Driven Deviation Mode (ADR-009) ‚Äî User feature request
2. +10% ‚Üí Mermaid Diagrams (ADR-010) ‚Äî Documentation improvement
3. +28% ‚Üí Smart UI Components ‚Äî Feature expansion
4. **Total: 58% > 25% threshold**

**Root Cause:**
Incremental feature additions were individually approved (+5%, +10%) but cumulative impact (58%) was not re-evaluated against threshold.

**Current State:**
- 21 uncommitted files (.reasoning_rl4/*.json, *.jsonl)
- 6 commits (100% ADR score) not yet documented
- Phase E4 objectives 33% complete (2/7 Smart UI components)
- System health: Excellent (no technical blockers)

### Decision Options

**Option A: Accept Drift (Update Baseline)**
- **Action:** Save current Plan.RL4 v2.0 as new baseline
- **Effect:** Reset bias to 0%, E4 becomes new reference
- **Pros:**
  - ‚úÖ Clean slate for future tracking
  - ‚úÖ E4 objectives validated as strategic direction
  - ‚úÖ No feature rollback required
- **Cons:**
  - ‚ùå Original E3.3 goal abandoned
  - ‚ùå Baseline becomes moving target
  - ‚ùå Risk of continuous drift without accountability

**Option B: Recalibrate (Remove Non-Essential Features)**
- **Action:** Review E4 features, remove non-critical components
- **Candidates for removal:**
  - Mermaid diagrams (docs improvement, not core functionality)
  - DeviationModeIndicator UI (nice-to-have, not essential)
  - TimelineChart (visualization, can be Phase E5)
- **Target:** Reduce bias to <25% (remove ~33 points worth)
- **Pros:**
  - ‚úÖ Return to flexible threshold
  - ‚úÖ Preserve original E3.3 baseline
  - ‚úÖ Discipline maintained
- **Cons:**
  - ‚ùå Rollback work already done
  - ‚ùå Documentation improvements lost
  - ‚ùå User may feel restricted

**Option C: Continue (Acknowledge Deviation)**
- **Action:** Document 58% bias, proceed with P1 tasks only
- **Constraint:** No new features until E4 P1 complete
- **Pros:**
  - ‚úÖ No rollback, no baseline change
  - ‚úÖ Complete current commitments
  - ‚úÖ Re-evaluate at E4 completion
- **Cons:**
  - ‚ùå Bias remains high (58%)
  - ‚ùå Risk of further drift
  - ‚ùå Threshold becomes meaningless if ignored

### Recommendation

**Agent Recommendation: Option A (Accept Drift)**

**Rationale:**
1. **Incremental drift was intentional:** Each +5%, +10% decision was user-approved
2. **E4 objectives are valuable:** Smart UI with LLM-validated KPIs solves real UX problem ("Et alors ? C'est grave ?")
3. **No technical debt:** All features implemented cleanly (ADR-008, ADR-009, ADR-010 documented)
4. **Historical value:** Mermaid diagrams improve LLM context significantly
5. **Baseline stability:** v1.0 preserved in `.baseline/` for reference

**Implementation:**
```bash
# Save current state as new baseline
cp .reasoning_rl4/Plan.RL4 .reasoning_rl4/.baseline/Plan.RL4.v2.0

# Update Plan.RL4 metadata
version: 2.0
baseline_version: 2.0
bias: 0.0 (reset)
baseline_updated: 2025-11-12T15:43:27.534Z
```

**Consequences:**
- ‚úÖ Bias reset to 0%
- ‚úÖ E4 becomes new strategic direction
- ‚úÖ Future drift measured against E4 baseline
- ‚ö†Ô∏è Original E3.3 baseline archived (still readable in `.baseline/Plan.RL4.v1.0`)

### Alternatives Considered

**Why not Option B (Recalibrate)?**
- Rollback Mermaid diagrams ‚Üí Loses documentation value
- Remove UI features ‚Üí Incomplete E4 (user frustration)
- Cost/benefit: High effort, low gain

**Why not Option C (Continue)?**
- Ignoring threshold ‚Üí System becomes "flexible" in name only
- 58% bias indefinitely ‚Üí No accountability
- Risk: Drift to 80%+ without re-evaluation

### Architecture Diagram

```mermaid
graph TD
    A["Baseline v1 0<br/>E3 3 Objectives"] --> B["Incremental Drift"]
    B --> C["+5% ADR-009<br/>UI Mode Selector"]
    B --> D["+10% ADR-010<br/>Mermaid Diagrams"]
    B --> E["+28% Smart UI<br/>Components"]
    C --> F["Current: 58% Bias"]
    D --> F
    E --> F
    
    F --> G{"Decision?"}
    G -->|Option A| H["Accept Drift<br/>New Baseline v2 0"]
    G -->|Option B| I["Recalibrate<br/>Remove Features"]
    G -->|Option C| J["Continue<br/>Acknowledge 58%"]
    
    H --> K["Bias Reset to 0%<br/>E4 = New Reference"]
    I --> L["Bias < 25%<br/>E3 3 = Reference"]
    J --> M["Bias = 58%<br/>No Change"]
    
    style F fill:#ff4d4d
    style H fill:#00c864
    style I fill:#ff9500
    style J fill:#667eea
```

**Key Decision Points:**
- **Problem:** 58% bias exceeds 25% threshold (flexible mode)
- **Root Cause:** Incremental approvals without cumulative re-evaluation
- **Solution:** Accept drift (update baseline) OR Recalibrate (remove features)
- **Recommendation:** Option A (accept drift, E4 valuable)

### Success Metrics

**If Option A chosen:**
- [ ] New baseline saved (`.baseline/Plan.RL4.v2.0`)
- [ ] Plan.RL4 metadata updated (bias: 0.0, baseline_version: 2.0)
- [ ] Context.RL4 recalculated with new baseline
- [ ] User satisfaction: "E4 objectives are my new strategic direction"

**If Option B chosen:**
- [ ] Features removed (document which ones)
- [ ] Bias recalculated (<25%)
- [ ] Plan.RL4 reverted to E3.3 scope
- [ ] User satisfaction: "I'm back on track with original plan"

**If Option C chosen:**
- [ ] Bias documented in all .RL4 files (58%)
- [ ] P1 tasks completed (no new features)
- [ ] Re-evaluation scheduled at E4 completion
- [ ] User satisfaction: "I understand the tradeoff"

### Implementation Status

**Pending User Decision:**
This ADR is **proposed** and requires user approval. The system will:
1. Wait for user response in next snapshot
2. Execute chosen option (A/B/C)
3. Update all .RL4 files accordingly
4. Mark this ADR as **accepted** once decision made

### Related ADRs
- ADR-007: Agent Self-Deviation Detection (original Deviation Guard)
- ADR-009: UI-Driven Deviation Mode (flexible threshold 25%)
- ADR-010: Smart UI with LLM-Validated KPIs (major feature addition)

### Uncommitted Commits (Potential ADRs)

**6 commits scored 100% for ADR detection:**

1. **b21ac31** - feat(rl4): Smart UI Phase 1 - ADR-010 + KPI Instructions (No Hallucinations)
   - Files: 33, Lines: 7,093 (+6,784/-309)
   - Core: Yes, Type: feature
   - **Needs ADR?** Already documented as ADR-010 ‚úÖ

2. **e41ff8c** - fix(rl4): UI i18n (French‚ÜíEnglish) + Adaptive Deviation Modes
   - Files: 31, Lines: 3,903 (+3,667/-236)
   - Core: Yes, Type: fix
   - **Needs ADR?** Internationalization decision + mode adaptation logic

3. **97e4843** - fix(mermaid): Remove dots from labels - Syntax error fix
   - Files: 18, Lines: 773 (+634/-139)
   - Core: No, Type: fix
   - **Needs ADR?** Low priority (syntax fix)

4. **f9d61c4** - feat(rl4): Mermaid Diagrams + Phase Evolution Tracking - Documentation Enhancement
   - Files: 25, Lines: 1,925 (+1,801/-124)
   - Core: No, Type: feature
   - **Needs ADR?** Already documented as ADR-010 context ‚úÖ

5. **7e358cb** - feat(rl4): ADR-009 UI-Driven Deviation Mode - Complete Implementation
   - Files: 30, Lines: 3,020 (+2,849/-171)
   - Core: Yes, Type: feature
   - **Needs ADR?** Already documented as ADR-009 ‚úÖ

6. **140406e** - feat(rl4): Phase E3.3‚ÜíE4 - Vision Finale + Deviation Guard + ADR Auto-Detection
   - Files: 266, Lines: 445,554 (+386,487/-59,067)
   - Core: Yes, Type: feature
   - **Needs ADR?** Already documented as ADR-008 ‚úÖ

**Action Required:** Only commit **e41ff8c** (i18n + adaptive modes) needs dedicated ADR documentation.


